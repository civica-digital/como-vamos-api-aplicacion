{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando Variables de pereira\n",
      "Cargando Variables de yumbo\n",
      "Cargando Variables de ibague\n",
      "Cargando Variables de manizales\n",
      "Cargando Variables de bogota\n",
      "Cargando Variables de cartagena\n",
      "Cargando Variables de medellin\n",
      "Cargando Variables de cali\n",
      "Cargando Variables de bucaramanga-metropolitana\n",
      "Cargando Variables de valledupar\n",
      "Cargando Variables de Pereira\n",
      "Cargando Variables de Yumbo\n",
      "Cargando Variables de Ibagué\n",
      "Cargando Variables de Manizales\n",
      "Cargando Variables de Bogotá"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import Levenshtein\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from math import isnan\n",
    "import simplejson as json\n",
    "\n",
    "\n",
    "\n",
    "DATADIRECTORY = \"data\"\n",
    "OBJECTIVEDATA_STRING = \"objetivo\"\n",
    "SUBJECTIVEDATA_STRING = \"subjetivo\"\n",
    "OBJECTIVEDATA_VERBOSE = \"indicadores\"\n",
    "SUBJECTIVEDATA_VERBOSE = \"encuestas\"\n",
    "DICTIONARY_STRING = \"diccionario\"\n",
    "DATA_STRING = \"datos\"\n",
    "\n",
    "\n",
    "#Diccionario provisional de ciudades\n",
    "cities = []\n",
    "cities_pretty_name = {\"bogota\":\"Bogotá\", \"cartagena\":\"Cartagena\", \"bucaramanga-metropolitana\":\"Bucaramanga Metropolitana\", \"cali\":\"Cali\", \"ibague\": \"Ibagué\", \"manizales\": \"Manizales\", \"medellin\":\"Medellín\", \"pereira\":\"Pereira\", \"valledupar\":\"Valledupar\", \"yumbo\": \"Yumbo\"}\n",
    "#cities_pretty_name = {\"bogota\":\"Bogotá\"}\n",
    "\n",
    "\n",
    "def return_city_files(allcityfiles,city):\n",
    "    cityfiles = []\n",
    "    for filename in allcityfiles:\n",
    "        if city in filename:\n",
    "            cityfiles.append(filename)\n",
    "    return(cityfiles)\n",
    "\n",
    "def identify_data_type(cityfiles):\n",
    "    datatype_byfilename = {}\n",
    "    for filename in cityfiles:\n",
    "        ratio_objective = Levenshtein.ratio(filename,OBJECTIVEDATA_VERBOSE)\n",
    "        ratio_subjetive = Levenshtein.ratio(filename,SUBJECTIVEDATA_VERBOSE)\n",
    "        if ratio_objective > ratio_subjetive:\n",
    "            datatype = OBJECTIVEDATA_STRING\n",
    "        else:\n",
    "            datatype = SUBJECTIVEDATA_STRING\n",
    "        if DICTIONARY_STRING in filename:\n",
    "            filetype = DICTIONARY_STRING\n",
    "        else:\n",
    "            filetype = DATA_STRING\n",
    "        datatype_byfilename[filename] = {\"datatype\":datatype,\"filetype\":filetype}\n",
    "    return(datatype_byfilename)\n",
    "\n",
    "def return_allcityfiles():\n",
    "    allcityfiles = os.listdir(DATADIRECTORY)\n",
    "    return allcityfiles\n",
    "\n",
    "def get_data_type(files_data_type,type_string):\n",
    "    dictionaries = {}\n",
    "    for filename in files_data_type:\n",
    "        if files_data_type[filename][\"filetype\"] == type_string:\n",
    "            dictionaries[files_data_type[filename][\"datatype\"]] =filename\n",
    "    return(dictionaries)\n",
    "\n",
    "def dict_key_by_value(dict_to_search, value):\n",
    "    for key in dict_to_search:\n",
    "        if dict_to_search[key]==value:\n",
    "            return key\n",
    "\n",
    "def string_cleaner_for_dictionary(source_string):\n",
    "    midstring_switch = str(source_string).replace(\"': '\",\"MIDSTRINGSIGNAL\")\n",
    "    endstring_switch = midstring_switch.replace(\"', '\", \"ENDOFSTRINGSIGNAL\")\n",
    "    quote_removal = endstring_switch.replace(\"'\",\"\")\n",
    "    double_quote_removal = quote_removal.replace('\"',\"\")\n",
    "    midstring_backinplace = double_quote_removal.replace(\"MIDSTRINGSIGNAL\",\"': '\")\n",
    "    endstring_backinplace = midstring_backinplace.replace(\"ENDOFSTRINGSIGNAL\",\"', '\")\n",
    "    doublequote_addition = \"{'\"+str(endstring_backinplace[1:-1])+\"'}\"\n",
    "    switch_quote_type= doublequote_addition.replace(\"'\",'\"')\n",
    "    return switch_quote_type\n",
    "\n",
    "def extract_data_columns(year_string,variable_name,data_file):\n",
    "    extracted_data = data_file[[year_string,variable_name]]\n",
    "    extracted_data = extracted_data[pd.notnull(data_file[variable_name])]\n",
    "    return extracted_data\n",
    "\n",
    "def average_per_year(year_string, variable_name, filtered_data,data_type):\n",
    "    data_return = []\n",
    "    astype_data = filtered_data.convert_objects(convert_numeric=True)\n",
    "    if data_type == \"subjective\":\n",
    "        astype_data = astype_data[(astype_data[variable_name] >= 1.0) & (astype_data[variable_name]<=5.0)]\n",
    "    ave_data = astype_data.groupby(year_string).mean()\n",
    "    data_availability = ave_data[variable_name].keys()\n",
    "    for key in data_availability:\n",
    "        data_return.append({\"year\":int(key),\"value\":str(ave_data[variable_name][key])})\n",
    "    return data_return\n",
    "\n",
    "def responses_per_year(year_string, variable_name, filtered_data, responses_variable):\n",
    "    data_return = []\n",
    "    unique_years = np.unique(filtered_data[[year_string]])\n",
    "    for year in unique_years:\n",
    "        yearly_sum = {}\n",
    "        yearly_data = filtered_data[filtered_data[year_string]==year]\n",
    "        yearly_responses = {}\n",
    "        for i, year_indicator in yearly_data.iterrows():\n",
    "            string_choices = year_indicator[variable_name]\n",
    "            string_array_choices = string_choices.split(\";\")\n",
    "            for choice in string_array_choices:\n",
    "                if choice in yearly_responses:\n",
    "                    yearly_responses[choice] = yearly_responses[choice] + 1\n",
    "                else:\n",
    "                    yearly_responses[choice] = 1\n",
    "\n",
    "        for key in yearly_responses:\n",
    "            try:\n",
    "                yearly_sum[responses_variable[variable_name][key]] = str(yearly_responses[key])\n",
    "            except:\n",
    "                yearly_sum[key] = str(yearly_responses[key])\n",
    "        data_return.append({\"year\":int(year),\"value\":str(yearly_sum)})\n",
    "    return data_return\n",
    "\n",
    "def extract_city_variableinfo(files_data_type,output_json,city,responses):\n",
    "    dictionaries = get_data_type(files_data_type,DICTIONARY_STRING)\n",
    "    objective_dictionary = pd.read_csv(DATADIRECTORY + \"/\" + dictionaries[OBJECTIVEDATA_STRING],delimiter=\",\", encoding=\"utf-8\", dtype=np.string_ )\n",
    "    subjective_dictionary = pd.read_csv(DATADIRECTORY + \"/\" + dictionaries[SUBJECTIVEDATA_STRING],delimiter=\",\", encoding=\"utf-8\", dtype=np.string_ )\n",
    "\n",
    "    output_json.append({\"name\":cities_pretty_name[city], \"categories\": []})\n",
    "    output_json[-1][\"categories\"] = []\n",
    "\n",
    "    rings = list(objective_dictionary.anillo.unique())\n",
    "    \n",
    "    for extra_ring in list(subjective_dictionary.dimension.unique()):\n",
    "        if extra_ring not in rings:\n",
    "            rings.append(extra_ring)\n",
    "    \n",
    "    category_position_index = {}\n",
    "    for ring in rings:\n",
    "        output_json[-1][\"categories\"].append({\"name\" : ring,\"indicators\" : []})\n",
    "        category_position_index[ring] = len(output_json[-1][\"categories\"])-1\n",
    "\n",
    "    ## Filling objective data\n",
    "    for i, objective_dictionary_row in objective_dictionary.iterrows():\n",
    "        if objective_dictionary_row[\"id\"]==objective_dictionary_row[\"Indicador\"]: next\n",
    "        indicator_category = objective_dictionary_row[\"anillo\"]\n",
    "        category_position = category_position_index[indicator_category]\n",
    "        current_indicator_data = {\"name\" : objective_dictionary_row[\"id\"], \"type\":\"objetivo\", \"description\": objective_dictionary_row[\"Indicador\"]}\n",
    "        output_json[-1][\"categories\"][category_position_index[indicator_category]][\"indicators\"].append(current_indicator_data)\n",
    "        \n",
    "    responses_by_variable = {}\n",
    "    for i, subjective_dictionary_row in subjective_dictionary.iterrows():\n",
    "        if subjective_dictionary_row[\"variable\"]==subjective_dictionary_row[\"descripcion\"]: next\n",
    "        indicator_category = subjective_dictionary_row[\"dimension\"]\n",
    "        category_position = category_position_index[indicator_category]\n",
    "        if subjective_dictionary_row[\"tipo_respuestas\"] == \"ordinal\":\n",
    "            data_type = \"subjetivo ordinal\"\n",
    "        else:\n",
    "            data_type = \"subjetivo categorico\"\n",
    "        current_indicator_data = {\"name\" : subjective_dictionary_row[\"variable\"], \"type\":data_type, \"description\": subjective_dictionary_row[\"descripcion\"]}\n",
    "        output_json[-1][\"categories\"][category_position_index[indicator_category]][\"indicators\"].append(current_indicator_data)\n",
    "\n",
    "        clean_response_string = string_cleaner_for_dictionary(subjective_dictionary_row[\"respuestas\"])\n",
    "\n",
    "        try:\n",
    "            responses_by_variable[subjective_dictionary_row[\"variable\"]] = json.loads(clean_response_string)\n",
    "        except:\n",
    "            responses_by_variable[subjective_dictionary_row[\"variable\"]] = { \"0\": \"NaN\"}\n",
    "\n",
    "    \n",
    "    return output_json, responses_by_variable\n",
    "\n",
    "def generate_city_data():\n",
    "    client = MongoClient()\n",
    "    db = client.test\n",
    "\n",
    "    allcityfiles = return_allcityfiles()\n",
    "    output_variable_json = []\n",
    "    responses = {}\n",
    "    for city in cities_pretty_name:\n",
    "        print(\"Cargando Variables de \" + city)\n",
    "        city_files = return_city_files(allcityfiles,city)\n",
    "        files_data_type =identify_data_type(city_files)\n",
    "        output_variable_json, responses = extract_city_variableinfo(files_data_type,output_variable_json,city,responses)\n",
    "\n",
    "    with open('cities.json', 'w') as fp:\n",
    "        json.dump(output_variable_json, fp)\n",
    "    \n",
    "    with open (\"cities.json\", \"r\") as input_file:\n",
    "        data=input_file.read().replace('NaN', '\"NaN\"')\n",
    "    \n",
    "    with open (\"cities.json\", \"w\") as fp:\n",
    "        fp.write(data)\n",
    "\n",
    "\n",
    "    allcityfiles = return_allcityfiles()\n",
    "    for city_dictionary in output_variable_json:\n",
    "        city_pretty = city_dictionary[\"name\"]\n",
    "        print(\"Cargando Variables de \" + city_pretty)\n",
    "        city_plain_name = dict_key_by_value(cities_pretty_name,city_pretty)\n",
    "\n",
    "        city_files = return_city_files(allcityfiles,city_plain_name)\n",
    "        files_data_type =identify_data_type(city_files)\n",
    "        data_files = get_data_type(files_data_type,DATA_STRING)\n",
    "\n",
    "        objective_data = pd.read_csv(DATADIRECTORY + \"/\" + data_files[OBJECTIVEDATA_STRING],delimiter=\",\", encoding=\"utf-8\", dtype=np.string_ )\n",
    "        subjective_data = pd.read_csv(DATADIRECTORY + \"/\" + data_files[SUBJECTIVEDATA_STRING],delimiter=\",\", encoding=\"utf-8\", dtype=np.string_ )\n",
    "\n",
    "\n",
    "        for category_data in city_dictionary[\"categories\"]:\n",
    "            for indicator_data in category_data[\"indicators\"]:\n",
    "                variable_name = indicator_data[\"name\"]\n",
    "                variable_type = indicator_data[\"type\"]\n",
    "                try:\n",
    "                    if variable_type == \"objetivo\":\n",
    "                        extracted_data = extract_data_columns(\"ANIO\",variable_name,objective_data)\n",
    "                        values = average_per_year(\"ANIO\",variable_name,extracted_data,\"objective\")\n",
    "                    elif variable_type == \"subjetivo ordinal\":\n",
    "                        extracted_data = extract_data_columns(\"AÑO\",variable_name,subjective_data)\n",
    "                        values = average_per_year(\"AÑO\",variable_name,extracted_data,\"subjective\")\n",
    "                    else:\n",
    "                        extracted_data = extract_data_columns(\"AÑO\",variable_name,subjective_data)\n",
    "                        values = responses_per_year(\"AÑO\",variable_name,extracted_data,responses)\n",
    "                except:\n",
    "                    values = [{\"year\":int(2014),\"value\":[{\"Caso especial de los datos\": \"0\"}]}]\n",
    "                return_dict = {\"name\":variable_name, \"city\":city_pretty, \"type\":variable_type, \"value\":values}\n",
    "                db.test_cities.insert_one(return_dict)\n",
    "    return \"Success\"\n",
    "\n",
    "generate_city_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import Levenshtein\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NaN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b1b710edc7f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'NaN' is not defined"
     ]
    }
   ],
   "source": [
    "NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
